{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_from_directories():\n",
    "    \"\"\"\n",
    "    Load image paths and labels from the specified directory structure\n",
    "    which is one level above the current directory.\n",
    "    Returns train and validation data for the model.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import glob\n",
    "    \n",
    "    # Define data directories - one level above the current directory\n",
    "    base_dir = os.path.join(os.path.dirname(os.getcwd()), 'datasets/brain-tumor')\n",
    "    train_img_dir = os.path.join(base_dir, 'train/images')\n",
    "    train_label_dir = os.path.join(base_dir, 'train/labels')\n",
    "    val_img_dir = os.path.join(base_dir, 'valid/images')\n",
    "    val_label_dir = os.path.join(base_dir, 'valid/labels')\n",
    "    \n",
    "    print(f\"Loading data from: {base_dir}\")\n",
    "    \n",
    "    # Collect all image files\n",
    "    train_image_paths = sorted(glob.glob(os.path.join(train_img_dir, '*')))\n",
    "    val_image_paths = sorted(glob.glob(os.path.join(val_img_dir, '*')))\n",
    "    \n",
    "    # Get corresponding label files (assuming same filename with different extension)\n",
    "    train_labels = []\n",
    "    for img_path in train_image_paths:\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        # Remove extension and add label extension (adjust as needed)\n",
    "        base_name = os.path.splitext(img_filename)[0]\n",
    "        label_path = os.path.join(train_label_dir, f\"{base_name}.txt\")\n",
    "        \n",
    "        # Read and process label (assuming label files have class as first value)\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                # Parse the first value as class label\n",
    "                # This assumes YOLO format where first value is class\n",
    "                line = f.readline().strip()\n",
    "                if line:\n",
    "                    parts = line.split()\n",
    "                    class_id = int(parts[0])  # Extract class ID\n",
    "                    train_labels.append(class_id)\n",
    "                else:\n",
    "                    # Handle empty label file\n",
    "                    train_labels.append(0)  # Default to class 0 or whatever is appropriate\n",
    "        else:\n",
    "            # Handle missing label file\n",
    "            print(f\"Warning: No label found for {img_path}\")\n",
    "            train_labels.append(0)  # Default to class 0 or whatever is appropriate\n",
    "    \n",
    "    # Repeat for validation labels\n",
    "    val_labels = []\n",
    "    for img_path in val_image_paths:\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        base_name = os.path.splitext(img_filename)[0]\n",
    "        label_path = os.path.join(val_label_dir, f\"{base_name}.txt\")\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                line = f.readline().strip()\n",
    "                if line:\n",
    "                    parts = line.split()\n",
    "                    class_id = int(parts[0])\n",
    "                    val_labels.append(class_id)\n",
    "                else:\n",
    "                    val_labels.append(0)\n",
    "        else:\n",
    "            print(f\"Warning: No label found for {img_path}\")\n",
    "            val_labels.append(0)\n",
    "    \n",
    "    print(f\"Loaded {len(train_image_paths)} training images and {len(val_image_paths)} validation images\")\n",
    "    \n",
    "    return train_image_paths, train_labels, val_image_paths, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\TPS-Sean/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:13<00:00, 40.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16Transfer(\n",
      "  (vgg16): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace=True)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace=True)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.3, inplace=False)\n",
      "      (3): Linear(in_features=256, out_features=1, bias=True)\n",
      "      (4): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Trainable parameters:\n",
      "vgg16.classifier.0.weight: torch.Size([256, 25088])\n",
      "vgg16.classifier.0.bias: torch.Size([256])\n",
      "vgg16.classifier.3.weight: torch.Size([1, 256])\n",
      "vgg16.classifier.3.bias: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "\n",
    "class VGG16Transfer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16Transfer, self).__init__()\n",
    "        \n",
    "        # Load pretrained VGG16 model with IMAGENET1K_V1 weights\n",
    "        self.vgg16 = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Freeze all layers in the VGG16 model\n",
    "        for param in self.vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Replace the classifier with our custom classifier\n",
    "        self.vgg16.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 256),  # VGG16's last conv layer outputs 25088 features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),        # Dropout after dense layer and ReLU\n",
    "            nn.Linear(256, 1),      # Binary classification (1 output neuron)\n",
    "            nn.Sigmoid()            # Sigmoid activation for binary classification\n",
    "        )\n",
    "        \n",
    "        # Unfreeze only the new dense layer (256 units)\n",
    "        for param in self.vgg16.classifier[0].parameters():  # First Linear layer (256 units)\n",
    "            param.requires_grad = True\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.vgg16(x)\n",
    "\n",
    "# Get the transforms for preprocessing\n",
    "transforms = VGG16_Weights.IMAGENET1K_FEATURES.transforms()\n",
    "\n",
    "# Create model instance\n",
    "model = VGG16Transfer()\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Verify which layers are trainable\n",
    "print(\"\\nTrainable parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: E:\\SDS-CP024-neurovision\\submissions-team\\andy-chen\\model_training\\datasets/brain-tumor\n",
      "Loaded 878 training images and 223 validation images\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_image_paths, train_labels, val_image_paths, val_labels = load_data_from_directories()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BrainTumorDataset(train_image_paths, train_labels, transform=transforms)\n",
    "val_dataset = BrainTumorDataset(val_image_paths, val_labels, transform=transforms)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "model = VGG16Transfer()\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels.view(-1, 1)).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                labels = labels.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels.view(-1, 1))\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels.view(-1, 1)).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Print statistics\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.2f}%')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:\n",
      "Train Loss: 39.3865 - Train Acc: 48.41%\n",
      "Val Loss: 27.9017 - Val Acc: 63.68%\n",
      "--------------------------------------------------\n",
      "Epoch 2/20:\n",
      "Train Loss: 35.6404 - Train Acc: 47.72%\n",
      "Val Loss: 26.5078 - Val Acc: 63.68%\n",
      "--------------------------------------------------\n",
      "Epoch 3/20:\n",
      "Train Loss: 34.9320 - Train Acc: 47.72%\n",
      "Val Loss: 26.4161 - Val Acc: 63.68%\n",
      "--------------------------------------------------\n",
      "Epoch 4/20:\n",
      "Train Loss: 34.0578 - Train Acc: 47.72%\n",
      "Val Loss: 26.2093 - Val Acc: 63.68%\n",
      "--------------------------------------------------\n",
      "Epoch 5/20:\n",
      "Train Loss: 33.9660 - Train Acc: 47.72%\n",
      "Val Loss: 22.9951 - Val Acc: 63.68%\n",
      "--------------------------------------------------\n",
      "Epoch 6/20:\n",
      "Train Loss: 32.3692 - Train Acc: 51.14%\n",
      "Val Loss: 2.1443 - Val Acc: 63.68%\n",
      "--------------------------------------------------\n",
      "Epoch 7/20:\n",
      "Train Loss: 6.3645 - Train Acc: 57.29%\n",
      "Val Loss: 0.8238 - Val Acc: 38.57%\n",
      "--------------------------------------------------\n",
      "Epoch 8/20:\n",
      "Train Loss: 0.6296 - Train Acc: 65.15%\n",
      "Val Loss: 0.7942 - Val Acc: 37.67%\n",
      "--------------------------------------------------\n",
      "Epoch 9/20:\n",
      "Train Loss: 0.5737 - Train Acc: 67.08%\n",
      "Val Loss: 0.6873 - Val Acc: 62.33%\n",
      "--------------------------------------------------\n",
      "Epoch 10/20:\n",
      "Train Loss: 0.5108 - Train Acc: 72.78%\n",
      "Val Loss: 0.8512 - Val Acc: 43.50%\n",
      "--------------------------------------------------\n",
      "Epoch 11/20:\n",
      "Train Loss: 0.4909 - Train Acc: 76.20%\n",
      "Val Loss: 0.9715 - Val Acc: 39.91%\n",
      "--------------------------------------------------\n",
      "Epoch 12/20:\n",
      "Train Loss: 0.4467 - Train Acc: 78.47%\n",
      "Val Loss: 0.6881 - Val Acc: 57.85%\n",
      "--------------------------------------------------\n",
      "Epoch 13/20:\n",
      "Train Loss: 0.4393 - Train Acc: 78.13%\n",
      "Val Loss: 0.6451 - Val Acc: 66.82%\n",
      "--------------------------------------------------\n",
      "Epoch 14/20:\n",
      "Train Loss: 0.3973 - Train Acc: 82.23%\n",
      "Val Loss: 0.8741 - Val Acc: 57.85%\n",
      "--------------------------------------------------\n",
      "Epoch 15/20:\n",
      "Train Loss: 0.3557 - Train Acc: 84.62%\n",
      "Val Loss: 0.6087 - Val Acc: 69.96%\n",
      "--------------------------------------------------\n",
      "Epoch 16/20:\n",
      "Train Loss: 0.3167 - Train Acc: 87.02%\n",
      "Val Loss: 1.1954 - Val Acc: 41.26%\n",
      "--------------------------------------------------\n",
      "Epoch 17/20:\n",
      "Train Loss: 0.3342 - Train Acc: 87.36%\n",
      "Val Loss: 3.7224 - Val Acc: 36.77%\n",
      "--------------------------------------------------\n",
      "Epoch 18/20:\n",
      "Train Loss: 0.4081 - Train Acc: 84.51%\n",
      "Val Loss: 0.8442 - Val Acc: 63.23%\n",
      "--------------------------------------------------\n",
      "Epoch 19/20:\n",
      "Train Loss: 0.3520 - Train Acc: 84.17%\n",
      "Val Loss: 0.7552 - Val Acc: 53.81%\n",
      "--------------------------------------------------\n",
      "Epoch 20/20:\n",
      "Train Loss: 0.2639 - Train Acc: 89.75%\n",
      "Val Loss: 0.9709 - Val Acc: 48.88%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_venv",
   "language": "python",
   "name": "base_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
